{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Upgrade\n",
    "\n",
    "## Experimenting with new models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize imports and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External imports\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from keras.applications import (\n",
    "    DenseNet121,\n",
    "    EfficientNetV2S,\n",
    "    InceptionResNetV2,\n",
    "    ResNet50V2,\n",
    ")\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Path to the brain tumor dataset composed of two sub folders training and testing\n",
    "DATA_DIR = \"./data/brain_dataset\"\n",
    "COMBINED_DIR = \"./data/combined\"\n",
    "\n",
    "# Path to the brain tumor dataset for testing\n",
    "TRAINING_DATASET = \"./data/brain_dataset/training\"\n",
    "COMBINED_TRAINING_DATASET = \"./data/combined/training\"\n",
    "\n",
    "# Path to the brain tumor dataset for testing\n",
    "TESTING_DATASET = \"./data/brain_dataset/testing\"\n",
    "COMBINED_TESTING_DATASET = \"./data/combined/testing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNetV2S pre-trained model\n",
    "\n",
    "#### Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle pré-entraîné EfficientNetV2S sans la couche de classification\n",
    "base_model = EfficientNetV2S(\n",
    "    weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Ajouter une couche GlobalAveragePooling2D pour réduire la dimensionalité\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Ajouter une couche dense pour la classification\n",
    "predictions = tf.keras.layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "# Créer le nouveau modèle en combinant le modèle pré-entraîné et les nouvelles couches\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Congeler les couches du modèle pré-entraîné\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Charger les données d'entraînement et de validation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAINING_DATASET, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    TESTING_DATASET, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# Entraîner le modèle\n",
    "efficientnet_history = model.fit(\n",
    "    train_generator, epochs=50, validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Alternatively, if you want to evaluate on a separate test dataset:\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TESTING_DATASET, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Alternatively, if you want to evaluate on a separate test dataset:\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TESTING_DATASET, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Retrieve training and validation accuracy from history\n",
    "train_acc = efficientnet_history.history[\"accuracy\"]\n",
    "val_acc = efficientnet_history.history[\"val_accuracy\"]\n",
    "\n",
    "# Create traces\n",
    "train_trace = go.Scatter(\n",
    "    x=list(range(1, len(train_acc) + 1)),\n",
    "    y=train_acc,\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Training acc\",\n",
    "    marker=dict(color=\"darkorange\", symbol=\"circle\"),\n",
    ")\n",
    "\n",
    "val_trace = go.Scatter(\n",
    "    x=list(range(1, len(val_acc) + 1)),\n",
    "    y=val_acc,\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Validation acc\",\n",
    "    marker=dict(color=\"green\", symbol=\"square\"),\n",
    ")\n",
    "\n",
    "# Create layout\n",
    "layout = go.Layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title=\"Training and Validation Accuracy\",\n",
    "    xaxis_title=\"Epochs\",\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    ")\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure(data=[train_trace, val_trace], layout=layout)\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionResNetV2 pre-trained model\n",
    "\n",
    "#### Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle pré-entraîné InceptionResNetV2 sans la couche de classification\n",
    "base_model = InceptionResNetV2(\n",
    "    weights=\"imagenet\", include_top=False, input_shape=(299, 299, 3)\n",
    ")\n",
    "\n",
    "# Ajouter une couche GlobalAveragePooling2D pour réduire la dimensionalité\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Ajouter une couche dense pour la classification\n",
    "predictions = tf.keras.layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "# Créer le nouveau modèle en combinant le modèle pré-entraîné et les nouvelles couches\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Congeler les couches du modèle pré-entraîné\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Charger les données d'entraînement et de validation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAINING_DATASET, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    TESTING_DATASET, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# Entraîner le modèle\n",
    "inceptionresnet_history = model.fit(\n",
    "    train_generator, epochs=75, validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve training and validation accuracy from history\n",
    "train_acc = inceptionresnet_history.history[\"accuracy\"]\n",
    "val_acc = inceptionresnet_history.history[\"val_accuracy\"]\n",
    "\n",
    "# Create traces\n",
    "train_trace = go.Scatter(\n",
    "    x=list(range(1, len(train_acc) + 1)),\n",
    "    y=train_acc,\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Training acc\",\n",
    "    marker=dict(color=\"darkorange\", symbol=\"circle\"),\n",
    ")\n",
    "\n",
    "val_trace = go.Scatter(\n",
    "    x=list(range(1, len(val_acc) + 1)),\n",
    "    y=val_acc,\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Validation acc\",\n",
    "    marker=dict(color=\"green\", symbol=\"square\"),\n",
    ")\n",
    "\n",
    "# Create layout\n",
    "layout = go.Layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title=\"InceptionResNetV2 Training and Validation Accuracy\",\n",
    "    xaxis_title=\"Epochs\",\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    ")\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure(data=[train_trace, val_trace], layout=layout)\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n",
    "\n",
    "# Evaluating the model on the testing dataset\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Alternatively, if you want to evaluate on a separate test dataset:\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TESTING_DATASET, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle pré-entraîné InceptionResNetV2 sans la couche de classification\n",
    "base_model = InceptionResNetV2(\n",
    "    weights=\"imagenet\", include_top=False, input_shape=(299, 299, 3)\n",
    ")\n",
    "\n",
    "# Ajouter une couche GlobalAveragePooling2D pour réduire la dimensionalité\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Ajouter une couche dense pour la classification\n",
    "predictions = tf.keras.layers.Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "# Créer le nouveau modèle en combinant le modèle pré-entraîné et les nouvelles couches\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Congeler les couches du modèle pré-entraîné\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Charger les données d'entraînement et de validation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAINING_DATASET, target_size=(299, 299), batch_size=16, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    TESTING_DATASET, target_size=(299, 299), batch_size=16, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# Entraîner le modèle\n",
    "inceptionresnet_history_v2 = model.fit(\n",
    "    train_generator, epochs=75, validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve training and validation accuracy from history\n",
    "train_acc = inceptionresnet_history_v2.history[\"accuracy\"]\n",
    "val_acc = inceptionresnet_history_v2.history[\"val_accuracy\"]\n",
    "\n",
    "# Create traces\n",
    "train_trace = go.Scatter(\n",
    "    x=list(range(1, len(train_acc) + 1)),\n",
    "    y=train_acc,\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Training acc\",\n",
    "    marker=dict(color=\"darkorange\", symbol=\"circle\"),\n",
    ")\n",
    "\n",
    "val_trace = go.Scatter(\n",
    "    x=list(range(1, len(val_acc) + 1)),\n",
    "    y=val_acc,\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Validation acc\",\n",
    "    marker=dict(color=\"green\", symbol=\"square\"),\n",
    ")\n",
    "\n",
    "# Create layout\n",
    "layout = go.Layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title=\"InceptionResNetV2 Training and Validation Accuracy\",\n",
    "    xaxis_title=\"Epochs\",\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    ")\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure(data=[train_trace, val_trace], layout=layout)\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n",
    "\n",
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Alternatively, if you want to evaluate on a separate test dataset:\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TESTING_DATASET, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle pré-entraîné DenseNet121 sans la couche de classification\n",
    "base_model = DenseNet121(\n",
    "    weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Ajouter une couche GlobalAveragePooling2D pour réduire la dimensionalité\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Ajouter une couche dense pour la classification\n",
    "predictions = Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "# Créer le nouveau modèle en combinant le modèle pré-entraîné et les nouvelles couches\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Congeler les couches du modèle pré-entraîné\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Charger les données d'entraînement et de validation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAINING_DATASET, target_size=(224, 224), batch_size=16, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    TESTING_DATASET, target_size=(224, 224), batch_size=16, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(train_generator, epochs=50, validation_data=validation_generator)\n",
    "\n",
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Alternatively, if you want to evaluate on a separate test dataset:\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TESTING_DATASET, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ResNet50V2 from keras.application as pre trained model with imagenet weight\n",
    "base_model = ResNet50V2(\n",
    "    weights=\"imagenet\", classes=4, input_shape=(224, 224, 3), include_top=False\n",
    ")\n",
    "\n",
    "# Ajouter une couche GlobalAveragePooling2D pour réduire la dimensionalité\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Ajouter une couche dense pour la classification\n",
    "predictions = Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "# Créer le nouveau modèle en combinant le modèle pré-entraîné et les nouvelles couches\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Congeler les couches du modèle pré-entraîné\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Charger les données d'entraînement et de validation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    COMBINED_TRAINING_DATASET,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    COMBINED_TESTING_DATASET,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "# Checkpoint filepath to save the model\n",
    "checkpoint_filepath = \"checkpoint.ResNet50V2.keras\"\n",
    "\n",
    "# Checkpoint callback\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "# Entraîner le modèle avec le callback\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Alternatively, if you want to evaluate on a separate test dataset:\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    COMBINED_TESTING_DATASET,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ResNet50V2 from keras.application as pre trained model with imagenet weight\n",
    "base_model = ResNet50V2(\n",
    "    weights=\"imagenet\", classes=4, input_shape=(224, 224, 3), include_top=False\n",
    ")\n",
    "\n",
    "# Ajouter une couche GlobalAveragePooling2D pour réduire la dimensionalité\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Ajouter une couche dense pour la classification\n",
    "predictions = Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "# Créer le nouveau modèle en combinant le modèle pré-entraîné et les nouvelles couches\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Congeler les couches du modèle pré-entraîné\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Charger les données d'entraînement et de validation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    COMBINED_TRAINING_DATASET,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    COMBINED_TESTING_DATASET,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "# Checkpoint filepath to save the model\n",
    "checkpoint_filepath = \"checkpoint.ResNet50V2-batch16.keras\"\n",
    "\n",
    "# Checkpoint callback\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "# Entraîner le modèle avec le callback\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    ")\n",
    "\n",
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Alternatively, if you want to evaluate on a separate test dataset:\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    COMBINED_TESTING_DATASET,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Alternatively, if you want to evaluate on a separate test dataset:\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TESTING_DATASET, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Retrieve training and validation accuracy from history\n",
    "train_acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "# Create traces\n",
    "train_trace = go.Scatter(\n",
    "    x=list(range(1, len(train_acc) + 1)),\n",
    "    y=train_acc,\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Training acc\",\n",
    "    marker=dict(color=\"darkorange\", symbol=\"circle\"),\n",
    ")\n",
    "\n",
    "val_trace = go.Scatter(\n",
    "    x=list(range(1, len(val_acc) + 1)),\n",
    "    y=val_acc,\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Validation acc\",\n",
    "    marker=dict(color=\"green\", symbol=\"square\"),\n",
    ")\n",
    "\n",
    "# Create layout\n",
    "layout = go.Layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title=\"Training and Validation Accuracy\",\n",
    "    xaxis_title=\"Epochs\",\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    ")\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure(data=[train_trace, val_trace], layout=layout)\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras import utils\n",
    "\n",
    "classifier = load_model(\"ResNet50V2-32.h5\")\n",
    "\n",
    "\n",
    "def new_prediction(path):\n",
    "    # Charger l'image\n",
    "    test_image = utils.load_img(path, target_size=(224, 224))\n",
    "\n",
    "    # Convertir l'image en tableau et redimensionner les pixels\n",
    "    test_image = utils.img_to_array(test_image)\n",
    "    test_image /= 255.0\n",
    "\n",
    "    # Ajouter une dimension de lot à l'image\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "    # Effectuer la prédiction en utilisant la fonction predict du modèle\n",
    "    result = classifier.predict(test_image)\n",
    "\n",
    "    # Déterminer la classe prédite et la probabilité maximale\n",
    "    class_pred = \"\"\n",
    "    if np.argmax(result) == 0:\n",
    "        class_pred = \"glioma_tumor\"\n",
    "    elif np.argmax(result) == 1:\n",
    "        class_pred = \"meningioma_tumor\"\n",
    "    elif np.argmax(result) == 2:\n",
    "        class_pred = \"no_tumor\"\n",
    "    elif np.argmax(result) == 3:\n",
    "        class_pred = \"pituitary_tumor\"\n",
    "    return [class_pred, np.max(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction(\"./dataset/combined/testing/glioma_tumor/G_0057.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
